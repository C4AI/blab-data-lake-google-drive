"""Interacts with Google Drive API, downloads files and their metadata."""

from __future__ import annotations

from dateutil import parser as timestamp_parser
from dataclasses import dataclass, field
from datetime import datetime
from functools import lru_cache
from google.oauth2 import service_account
from googleapiclient.http import MediaIoBaseDownload
from googleapiclient.discovery import build, Resource
from hashlib import md5
from httplib2 import Http
from overrides import overrides
from pathlib import Path
from structlog import getLogger

from .config import GoogleDriveConfig
from .formats import ExportFormat

_logger = getLogger(__name__)


_FILE_FIELDS = ', '.join(['id', 'name', 'parents', 'kind', 'mimeType',
                         'webViewLink', 'md5Checksum', 'size', 'createdTime',
                          'modifiedTime', 'lastModifyingUser',
                          'headRevisionId', 'iconLink', 'capabilities'
                          ])


@dataclass
class RemoteFile:
    """Represents a regular file or a directory stored on Google Drive."""

    name: str
    """File name (without directory)"""

    id: str
    """File id (generated by Google Drive)"""

    mime_type: str
    """MIME type"""

    created_time: datetime
    """Creation timestamp"""

    modified_time: datetime
    """Last modification timestamp"""

    modified_by: str
    """Name of the user who made the last change"""

    web_url: str
    """URL to access the file on a browser"""

    icon_url: str
    """URL of the file icon (does not require authentication)"""

    parent: RemoteDirectory | None
    """Parent directory"""

    @property
    def parent_id(self) -> str | None:
        """Id of the parent directory.

        Returns:
            The id of the parent directory, or ``None`` if this is the root
        """
        return p.id if (p := self.parent) is not None else None

    def print_tree(self, _pfx: list[bool] | None = None) -> None:
        """Print the tree file names to standard output (for debugging)."""
        if _pfx is None:
            _pfx = []
        for i, p in enumerate(_pfx[:-1]):
            print(' ┃ ' if p else '   ', end=' ')
        if _pfx:
            print(' ┠─' if _pfx[-1] else ' ┖─', end=' ')
        print(self.name)


@dataclass
class RemoteDirectory(RemoteFile):
    """Represents a directory stored on Google Drive."""

    children: list[RemoteFile] = field(default_factory=list)
    """Subdirectories and regular files in this directory"""

    is_root: bool = False
    """Whether this directory is the root specified in the settings
        (not necessarily the root on Google Drive)"""

    def _fill_children(self, gdservice: GoogleDriveService,
                       gd_config: GoogleDriveConfig) -> None:
        service = gdservice.service
        q_items = ['not trashed']
        if self.id:
            q_items.append(f"'{self.id}' in parents")
        q = ' and '.join(q_items)
        shared_drive_id = gd_config.shared_drive_id
        params = dict(
            supportsAllDrives=bool(shared_drive_id),
            includeItemsFromAllDrives=bool(shared_drive_id),
            driveId=shared_drive_id or None,
            corpora='drive' if shared_drive_id else 'user',
            pageSize=int(gd_config.page_size),
            fields=f'nextPageToken, files({_FILE_FIELDS})',
            orderBy='folder, name',
            q=q
        )
        page_token = None
        children = []
        page = 0
        log = _logger.bind(id=self.id)
        while page_token is not None or page == 0:
            request = service.files().list(
                pageToken=page_token,
                **params
            )
            log.debug('requesting directory', page=page)
            results = request.execute(num_retries=gdservice.num_retries)
            children += results['files']
            page_token = results.get('nextPageToken', None)
            page += 1
        for f in children:
            metadata = [f['name'], f['id'], f['mimeType'],
                        timestamp_parser.parse(f['createdTime']),
                        timestamp_parser.parse(f['modifiedTime']),
                        f['lastModifyingUser']['displayName'],
                        f['webViewLink'], f['iconLink'],
                        self,
                        ]
            node: RemoteFile
            if f['mimeType'] == 'application/vnd.google-apps.folder':
                node = RemoteDirectory(*metadata)
                node._fill_children(gdservice, gd_config)
            else:
                export_extensions = list(map(
                    lambda fmt: fmt.extension, gdservice.export_formats().get(
                        f['mimeType'], [])))
                file_metadata = [
                    int(s) if (s := f.get('size', None)) is not None else None,
                    f.get('md5Checksum', None),
                    f.get('headRevisionId', None),
                    f.get('capabilities', {}).get('canDownload', False),
                    export_extensions
                ]
                node = RemoteRegularFile(*metadata, *file_metadata)
            self.children.append(node)

    @classmethod
    def get_tree(cls, gdservice: GoogleDriveService,
                 gd_config: GoogleDriveConfig) -> RemoteDirectory:
        """Fetch and return the directory tree from Google Drive.

        There is no depth limit.

        Args:
            gdservice: Google Drive service
            gd_config: configuration parameters

        Returns:
            an object representing the root directory defined
            by the ``SubTreeRootId`` field of `gd_config`.
        """
        service = gdservice.service
        this_id = gd_config.sub_tree_root_id or gd_config.shared_drive_id
        shared_drive_id = gd_config.shared_drive_id
        if this_id:
            request = service.files().get(
                fileId=this_id,
                supportsAllDrives=bool(shared_drive_id),
                fields=_FILE_FIELDS,
            )
            _logger.debug('requesting root directory', id=this_id)
            f = request.execute(num_retries=gdservice.num_retries)
            metadata = [f['name'], f['id'], f['mimeType'],
                        timestamp_parser.parse(f['createdTime']),
                        timestamp_parser.parse(f['modifiedTime']),
                        f['lastModifyingUser']['displayName'],
                        f['webViewLink'], f['iconLink'],
                        None,
                        ]
        else:
            metadata = ['', None, None, None, None, None, None, None, None]
        root = RemoteDirectory(*metadata, is_root=True)  # type: ignore
        root._fill_children(gdservice, gd_config)
        return root

    def flatten(self) -> dict[str, RemoteFile]:
        """Convert the tree to a flat dictionary.

        Returns:
            a flat dictionary where files are mapped by their ids
        """
        d: dict[str, RemoteFile] = {self.id: self}
        for c in self.children:
            d.update(c.flatten() if isinstance(c, RemoteDirectory)
                     else {c.id: c})
        return d

    @overrides
    def print_tree(self, _pfx: list[bool] | None = None) -> None:
        super().print_tree(_pfx)
        if _pfx is None:
            _pfx = []
        for child in self.children[:-1]:
            child.print_tree(_pfx + [True])
        if self.children:
            self.children[-1].print_tree(_pfx + [False])


@dataclass
class RemoteRegularFile(RemoteFile):
    """Represents a regular file stored on Google Drive.

    Includes Google Workspace files.
    """

    size: int
    """File size in bytes"""

    md5_checksum: str
    """File hash"""

    head_revision_id: str
    """Current version id (generated by Google Drive)"""

    can_download: bool
    """Whether the file can be downloaded"""

    export_extensions: list[str] | None = None
    """Formats to which a Google Workspace file can be exported"""

    @property
    def local_name(self) -> str:
        """Local file name (without path).

        For Google Workspace files, extension is not included.

        Returns:
            Local file name
        """
        if self.is_google_workspace_file:
            return self.id + '_' + \
                self.modified_time.strftime('%Y%m%d_%H%M%S%f')
        else:
            return self.id + \
                '_' + (self.head_revision_id or '') + \
                '_' + (self.md5_checksum or '')

    @property
    def is_google_workspace_file(self) -> bool:
        """Whether this is a Google Workspace file.

        Returns:
            ``True`` if and only if the MIME type starts
            with ``application/vnd.google-apps``
        """
        return self.mime_type.startswith('application/vnd.google-apps')

    @classmethod
    def _md5(cls, fn: str) -> str:
        md5_hash = md5()
        with open(fn, 'rb') as fd:
            for chunk_4k in iter(lambda: fd.read(4096), b''):
                md5_hash.update(chunk_4k)
        return md5_hash.hexdigest()

    def download(self, gdservice: GoogleDriveService, file_name: str,
                 skip_if_size_matches: bool = True,
                 also_check_md5: bool = False) -> bool | None:
        """Download the file.

        Args:
            gdservice: Google Drive service
            file_name: local file name to store the contents
            skip_if_size_matches: do not download if file already exists
                and its size matches the expected value
            also_check_md5: in addition to the size, also check file hash
                and only skip the download if it matches

        This method does not apply to Google Workspace files.

        Returns:
            ``True`` if the download completed successfully,
            ``False`` if some error occurred and
            ``None`` if download was skipped because the file already existed
        """
        if self.is_google_workspace_file:
            return False

        service = gdservice.service
        log = _logger.bind(id=self.id, name=self.name, local_name=file_name)

        if skip_if_size_matches:
            p = Path(file_name)
            if p.is_file() and p.stat().st_size == self.size:
                if not also_check_md5:
                    log.info('skipping download, size matches', size=self.size)
                    return None
                if self._md5(file_name) == self.md5_checksum:
                    log.info('skipping download, size and hash match',
                             size=self.size, md5_checksum=self.md5_checksum)
                    return None
        log.info('downloading file')
        with open(file_name, 'wb') as fd:
            request = service.files().get_media(
                fileId=self.id,
            )
            downloader = MediaIoBaseDownload(fd, request)
            completed = False
            while not completed:
                status, completed = downloader.next_chunk(
                    num_retries=gdservice.num_retries)
        return True

    def export(self, gdservice: GoogleDriveService,
               formats: list[ExportFormat],
               file_name_without_extension: str) -> bool | None:
        """Download exported versions of the file.

        Args:
            gdservice: Google Drive service
            formats: list of formats
            file_name_without_extension: local file name without extension
                to store the contents

        This method only applies to to Google Workspace files.

        Returns:
            ``True`` if the download completed successfully,
            ``False`` if some error occurred and
            ``None`` if download was skipped because the file already existed
        """
        if not self.is_google_workspace_file:
            return False

        service = gdservice.service
        log = _logger.bind(id=self.id, name=self.name,
                           local_name_without_ext=file_name_without_extension)

        log.info('downloading exported file')
        for fmt in formats:
            file_name = file_name_without_extension + '.' + fmt.extension
            with open(file_name, 'wb') as fd:
                request = service.files().export(
                    fileId=self.id,
                    mimeType=fmt.mime_type,
                )
                downloader = MediaIoBaseDownload(fd, request)
                completed = False
                while not completed:
                    status, completed = downloader.next_chunk(
                        num_retries=gdservice.num_retries)
        return True


class GoogleDriveService:
    """A class that wraps Google Drive API consumer to get the directory tree.

    This class provides a method that obtains the directory tree
    from a Google Drive directory or shared drive.
    """

    def __init__(self, gd_config: GoogleDriveConfig,
                 _http: Http | None = None,
                 _service: Resource | None = None):
        """
        Args:
            gd_config: service configuration
            _service: an optional existing :class:`Resource` instance to reuse
                (usually should be `None` except for testing purposes)
            _http: used to make HTTP requests (usually should be `None`
                except for testing purposes)

        For a description of the expected keys and values of `gd_config`,
        see the section ``GoogleDrive`` in
        :download:`the documentation <../README_CONFIG.md>`.

        In most cases, `_service` should be omitted and the attribute
        :attr:`service` will be set to a fresh instance created by the
        constructor.
        """  # noqa:D205,D400
        self.gd_config = gd_config
        """Configuration parameters"""

        self.service: Resource = _service or self.__get_service()
        """Google Drive service."""

    def __get_service(self, _http: Http | None = None) -> Resource:
        scopes = ['https://www.googleapis.com/auth/drive']
        cred = service_account.Credentials.from_service_account_file(
            self.gd_config.service_account_key_file_name, scopes=scopes)
        s = build('drive', 'v3', credentials=cred, cache_discovery=False)
        return s

    def get_tree(self) -> RemoteDirectory:
        """Fetch and return the directory tree from Google Drive.

        There is no depth limit.

        Returns:
            an object representing the root directory defined
            by the ``sub_tree_root_id`` field of :attr:`gd_config`.
        """
        return RemoteDirectory.get_tree(self, self.gd_config)

    @lru_cache(maxsize=1)
    def export_formats(self) -> dict[str, list[ExportFormat]]:
        """Get the supported formats to export Google Workspace files.

        Returns:
            A dictionary mapping Google Workspace file MIME types to
            the list of formats they can be exported to
        """
        request = self.service.about().get(fields='exportFormats')
        result = request.execute(num_retries=self.num_retries)
        return {k: list(map(
            lambda mt: ExportFormat.from_mime_type(mt), v))
            for k, v in result['exportFormats'].items()}

    def download_file(self, file: RemoteRegularFile, output_file: str,
                      skip_if_size_matches: bool = True,
                      also_check_md5: bool = False) -> bool | None:
        """Download a file from Google Drive.

        This method does not apply to Google Workspace files.

        Args:
            file: the file to download
            output_file: local file where the contents will be saved
            skip_if_size_matches: do not download if file already exists
                and its size matches the expected value
            also_check_md5: in addition to the size, also check file hash
                and only skip the download if it matches

        Returns:
            ``True`` if the download completed successfully,
            ``False`` if some error occurred and
            ``None`` if download was skipped because the file already existed
        """
        return file.download(self, output_file,
                             skip_if_size_matches, also_check_md5)

    @property
    def num_retries(self) -> int:
        """Return the number of times to retry the requests when they fail.

        See argument `num_retries` on
        `Google API Client Library documentation`_.

        .. _Google API Client Library documentation: https://googleapis.\
            github.io/google\
            -api-python-client/docs/epy/googleapiclient.http.\
            HttpRequest-class.html#execute

        Returns:
            maximum number of retries
        """
        return self.gd_config.retries

    def export_file(self, file: RemoteRegularFile, formats: list[ExportFormat],
                    output_file_without_extension: str) -> bool | None:
        """Download a file exported from Google Drive.

        This method only applies to Google Workspace files.

        Args:
            file: the file to download
            formats: list of formats
            output_file_without_extension: local file where the contents
                will be saved

        Returns:
            ``True`` if the download completed successfully,
            ``False`` if some error occurred and
            ``None`` if download was skipped because the file already existed
        """
        return file.export(self, formats, output_file_without_extension)
